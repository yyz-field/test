<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Cluster Restore on Longhorn Manual Test Cases</title>
    <link>https://longhorn.github.io/longhorn-tests/manual/pre-release/cluster-restore/</link>
    <description>Recent content in Cluster Restore on Longhorn Manual Test Cases</description>
    <generator>Hugo</generator>
    <language>en-us</language>
    <atom:link href="https://longhorn.github.io/longhorn-tests/manual/pre-release/cluster-restore/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Restore to a new cluster</title>
      <link>https://longhorn.github.io/longhorn-tests/manual/pre-release/cluster-restore/restore-to-a-new-cluster/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://longhorn.github.io/longhorn-tests/manual/pre-release/cluster-restore/restore-to-a-new-cluster/</guid>
      <description>&lt;h4 id=&#34;back-up-the-old-cluster&#34;&gt;Back up the old cluster&lt;/h4&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;Deploy the 1st cluster then install Longhorn system and Velero.&lt;/li&gt;&#xA;&lt;li&gt;Deploy some workloads using Longhorn volumes then write some data:&#xA;&lt;ol&gt;&#xA;&lt;li&gt;A simple pod using multiple volumes. And some volumes are using backing images.&lt;/li&gt;&#xA;&lt;li&gt;A StatefulSet.&lt;/li&gt;&#xA;&lt;li&gt;A Deployment with a RWX volume.&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;Config some recurring policies for the volumes.&lt;/li&gt;&#xA;&lt;li&gt;Create backups for all volumes.&lt;/li&gt;&#xA;&lt;li&gt;Create a cluster backup via Velero.&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;velero backup create lh-cluster --exclude-resources persistentvolumes,persistentvolumeclaims,backuptargets.longhorn.io,backupvolumes.longhorn.io,backups.longhorn.io,nodes.longhorn.io,volumes.longhorn.io,engines.longhorn.io,replicas.longhorn.io,backingimagedatasources.longhorn.io,backingimagemanagers.longhorn.io,backingimages.longhorn.io,sharemanagers.longhorn.io,instancemanagers.longhorn.io,engineimages.longhorn.io&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;h4 id=&#34;restore-to-a-new-cluster&#34;&gt;Restore to a new cluster&lt;/h4&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;Deploy the 2nd cluster then install Velero only. You can try with different cluster config (more nodes or disks) here.&lt;/li&gt;&#xA;&lt;li&gt;Restore the cluster backup. e.g.,&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;velero restore create --from-backup lh-cluster&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;&#xA;&lt;li&gt;Removing all old instance manager pods and backing image manager pods from namespace &lt;code&gt;longhorn-system&lt;/code&gt;. Since there is no corresponding InstanceManager CR or BackingImageManager CR for these old pods.&lt;/li&gt;&#xA;&lt;li&gt;Re-config nodes and disks for the restored Longhorn system if necessary.&lt;/li&gt;&#xA;&lt;li&gt;Re-create backing images.&lt;/li&gt;&#xA;&lt;li&gt;Restore all Longhorn volumes from the remote backup target.&lt;/li&gt;&#xA;&lt;li&gt;Update the access mode to &lt;code&gt;ReadWriteMany&lt;/code&gt; since all restored volumes are mode &lt;code&gt;ReadWriteOnce&lt;/code&gt; by default.&lt;/li&gt;&#xA;&lt;li&gt;Create PVCs and PVs with previous names for the restored volumes.&lt;/li&gt;&#xA;&lt;li&gt;Verify all workloads work fine with correct data.&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;hr&gt;&#xA;&lt;p&gt;GitHub issue link: &lt;a href=&#34;https://github.com/longhorn/longhorn/issues/3367&#34;&gt;https://github.com/longhorn/longhorn/issues/3367&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>Restore to an old cluster</title>
      <link>https://longhorn.github.io/longhorn-tests/manual/pre-release/cluster-restore/restore-to-an-old-cluster/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://longhorn.github.io/longhorn-tests/manual/pre-release/cluster-restore/restore-to-an-old-cluster/</guid>
      <description>&lt;p&gt;Notice that the behaviors will be different if the cluster node roles are different. e.g., A cluster contains 1 dedicated master node + 3 worker node is different from a cluster contains 3 nodes which are both master and worker.&#xA;This test may need to be validated for both kind of cluster.&lt;/p&gt;&#xA;&lt;h2 id=&#34;node-creation-and-deletion&#34;&gt;Node creation and deletion&lt;/h2&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;Deploy a 3-worker-node cluster then install Longhorn system.&lt;/li&gt;&#xA;&lt;li&gt;Deploy some workloads using Longhorn volumes then write some data.&lt;/li&gt;&#xA;&lt;li&gt;Create a cluster snapshot via Rancher.&lt;/li&gt;&#xA;&lt;li&gt;Add a new worker node for this cluster. Deploy workloads on this node.&lt;/li&gt;&#xA;&lt;li&gt;Restore the cluster.&lt;/li&gt;&#xA;&lt;li&gt;Follow the doc after the restore. Verify:&#xA;&lt;ol&gt;&#xA;&lt;li&gt;The new node is still in the Longhorn system. All necessary longhorn workloads will be on the node.&lt;/li&gt;&#xA;&lt;li&gt;The workloads and the volumes created in step 2 work fine after restarting.&lt;/li&gt;&#xA;&lt;li&gt;The data of the volumes created in step 4 can be recovered.&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;Create one more cluster snapshot.&lt;/li&gt;&#xA;&lt;li&gt;Delete one node all related volumes/replicas on the node.&lt;/li&gt;&#xA;&lt;li&gt;Restore the cluster.&lt;/li&gt;&#xA;&lt;li&gt;Follow the doc after the restore. Verify:&#xA;&lt;ol&gt;&#xA;&lt;li&gt;There is no corresponding Longhorn node CR.&lt;/li&gt;&#xA;&lt;li&gt;The Longhorn pods on the deleted node will be restored but they will become &lt;code&gt;Terminating&lt;/code&gt; after several minutes. Users need to force deleting them.&lt;/li&gt;&#xA;&lt;li&gt;The volumes or replicas CRs on the gone node will be restored. Users can clean up them.&lt;/li&gt;&#xA;&lt;li&gt;The workloads and the volumes not on the removed node work fine after restarting.&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;h2 id=&#34;longhorn-volume-recovery&#34;&gt;Longhorn volume recovery&lt;/h2&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;Launch a Longhorn system. Deploy one more compatible engine image.&lt;/li&gt;&#xA;&lt;li&gt;Prepare some volumes with workloads:&#xA;&lt;ol&gt;&#xA;&lt;li&gt;Create and attach volume A via UI. Write some data and do some snapshot operations. (Validate 1 case: The volume deleted after the cluster snapshot will be restored but is invalid)&lt;/li&gt;&#xA;&lt;li&gt;Deploy a single pod with volume B. Write some data, do some snapshot operations, and create some backups. (Validate 3 cases: &amp;lt;1&amp;gt; data modification won&amp;rsquo;t crash the whole volume; &amp;lt;2&amp;gt; backup info will be resynced; &amp;lt;3&amp;gt; users need to manual restart the single pod)&lt;/li&gt;&#xA;&lt;li&gt;Deploy a StatefulSet with volume C. Write some data and do some snapshot operations. (Validate 1 case: Users need to manually recover the volume if all existing replicas are replaced by new replicas)&lt;/li&gt;&#xA;&lt;li&gt;Deploy a StatefulSet with volume D. Write some data and do some snapshot operations. (Validate 2 cases: &amp;lt;1&amp;gt; volume can be recovered automatically if some replicas are removed and some new replicas are replenished; &amp;lt;2&amp;gt; snapshot info will be resynced;)&lt;/li&gt;&#xA;&lt;li&gt;Deploy a Deployment with volume E. Write some data and do some snapshot operations. (Validate 4 cases: &amp;lt;1&amp;gt; engine upgrade; &amp;lt;2&amp;gt; offline expansion)&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;Create a cluster snapshot via Rancher.&lt;/li&gt;&#xA;&lt;li&gt;Do the followings before the restore:&#xA;&lt;ol&gt;&#xA;&lt;li&gt;Delete volume A.&lt;/li&gt;&#xA;&lt;li&gt;Write more data to volume B and create more backups.&lt;/li&gt;&#xA;&lt;li&gt;Remove all current replicas one by one for volume C. Then all replicas of volume C are new replicas.&lt;/li&gt;&#xA;&lt;li&gt;Remove some replicas for volume D. Do snapshot creation, deletion, and revert.&lt;/li&gt;&#xA;&lt;li&gt;Scale down the workload. Upgrade volume E from the default image to another engine image. And do expansion.&lt;/li&gt;&#xA;&lt;li&gt;Create and attach volume F via UI. Write some data and do some snapshot operations. (Validate 1 case: Users need to manuall recover the volume if it&amp;rsquo;s created after the cluster snapshot)&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;Restore the cluster.&lt;/li&gt;&#xA;&lt;li&gt;Check the followings according to the doc:&#xA;&lt;ol&gt;&#xA;&lt;li&gt;Volume A is back. But there is no data in it. And users can re-delete it.&lt;/li&gt;&#xA;&lt;li&gt;Volume B can be reattached or keep attached with correct data. The backup info of volume B is resynced when the volume is reattahed. The pod can use the volume after restart.&lt;/li&gt;&#xA;&lt;li&gt;All old removed replicas are back and all newly rebuilt replicas in step4-3 disappear for volume C. There is no data in volume C. The data directories of the disappeared replicas are still on the node. Hence the data are be recovered by exporting a single replica volume.&lt;/li&gt;&#xA;&lt;li&gt;The old removed replicas are back and the newly rebuilt replicas in step4-4 disappear for volume D. The restored replicas will become failed then get rebuilt with correct data. The data directories of the disappeared replicas are still on the node.&lt;/li&gt;&#xA;&lt;li&gt;Volume E re-uses the default engine image, and gets stuck in shrinking the expanded size to the original size. By re-scaling down the workload, re-upgrade and re-expand the volume. The volume can work fine then.&lt;/li&gt;&#xA;&lt;li&gt;Volume F will disappear. The data directories of the disappeared replicas are still on the node. Hence the data are be recovered by exporting a single replica volume.&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;h2 id=&#34;longhorn-system-upgrade&#34;&gt;Longhorn system upgrade&lt;/h2&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;Install Longhorn system. Deploy one more compatible engine image.&lt;/li&gt;&#xA;&lt;li&gt;Deploy some workloads using Longhorn volumes then write some data.&lt;/li&gt;&#xA;&lt;li&gt;Create a cluster snapshot via Rancher.&lt;/li&gt;&#xA;&lt;li&gt;Upgrade the Longhorn system to a newer version. Then modify the settings or node configs (especially the configs introduced in the new version).&lt;/li&gt;&#xA;&lt;li&gt;Restore the cluster.&lt;/li&gt;&#xA;&lt;li&gt;Follow the doc after the restore. Verify:&#xA;&lt;ol&gt;&#xA;&lt;li&gt;The system re-upgrade should succeed.&lt;/li&gt;&#xA;&lt;li&gt;The modifications for the settings or configs in step 4 won&amp;rsquo;t be back. But users can re-modify them.&lt;/li&gt;&#xA;&lt;li&gt;The workloads and the volumes created in step 2 work fine after restarting.&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;hr&gt;&#xA;&lt;p&gt;GitHub issue link: &lt;a href=&#34;https://github.com/longhorn/longhorn/issues/2228&#34;&gt;https://github.com/longhorn/longhorn/issues/2228&lt;/a&gt;&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
