<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Upgrade on Longhorn Manual Test Cases</title>
    <link>https://longhorn.github.io/longhorn-tests/manual/pre-release/upgrade/</link>
    <description>Recent content in Upgrade on Longhorn Manual Test Cases</description>
    <generator>Hugo</generator>
    <language>en-us</language>
    <atom:link href="https://longhorn.github.io/longhorn-tests/manual/pre-release/upgrade/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Automatically Upgrading Longhorn Engine Test</title>
      <link>https://longhorn.github.io/longhorn-tests/manual/pre-release/upgrade/auto-upgrade-engine/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://longhorn.github.io/longhorn-tests/manual/pre-release/upgrade/auto-upgrade-engine/</guid>
      <description>&lt;h4&gt;Longhorn version &gt;= 1.1.1 &lt;/h4&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/longhorn/longhorn/issues/2152&#34;&gt;Reference ticket 2152&lt;/a&gt;&lt;/p&gt;&#xA;&lt;h3 id=&#34;test-basic-upgrade&#34;&gt;Test basic upgrade&lt;/h3&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;Install old Longhorn version. E.g., &amp;lt;= &lt;code&gt;v1.0.2&lt;/code&gt;&lt;/li&gt;&#xA;&lt;li&gt;Create a volume, attach it to a pod, write some data. Create a DR volume and leave it in the detached state.&lt;/li&gt;&#xA;&lt;li&gt;Upgrade to Longhorn master&lt;/li&gt;&#xA;&lt;li&gt;Set setting &lt;code&gt;concurrent automatic engine upgrade per node limit&lt;/code&gt; to 3&lt;/li&gt;&#xA;&lt;li&gt;Verify that volumes&amp;rsquo; engines are upgraded automatically.&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;h3 id=&#34;test-concurrent-upgrade&#34;&gt;Test concurrent upgrade&lt;/h3&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;Create a StatefulSet of scale 10 using 10 Longhorn volume. Set node selector so that all pods land on the same node.&lt;/li&gt;&#xA;&lt;li&gt;Upgrade Longhorn to use a newer default engine image&lt;/li&gt;&#xA;&lt;li&gt;In Longhorn UI and Longhorn manager logs, Verify that Longhorn doesn&amp;rsquo;t upgrade all volumes at the same time. Only 3 at a time.&lt;/li&gt;&#xA;&lt;li&gt;In Longhorn UI, while the concurrent value is set to limit 1, change the value to higher number and verify if the upgrade is happening as per the new value.&lt;/li&gt;&#xA;&lt;li&gt;Create stateful set pods with volume claim template, set the scale to 10 and in the configure options, select RWO and RWX. Verify the volumes created have RWX set as RWX takes precedence.&lt;/li&gt;&#xA;&lt;li&gt;While the auto upgrade is set, try to manually upgrade the image engine to the latest version. The manual upgrade should work and the image should be upgraded to the default version.&lt;/li&gt;&#xA;&lt;li&gt;Take backup for a volume when upgrade hasn&amp;rsquo;t started.&lt;/li&gt;&#xA;&lt;li&gt;Create 10 volumes and set concurrent upgrade limit to 2. When the upgrade starts, delete all the volumes. [Volumes are deleted and Longhorn UI is not corrupted.&lt;/li&gt;&#xA;&lt;li&gt;Deploy a workload with rwx scale 10 with persistent volume claim template and verify the volume created can be used for all of 10 pods.&lt;/li&gt;&#xA;&lt;li&gt;While upgrade is in progress, detach the volume from node and verify the detached volume is upgraded.&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;h3 id=&#34;test-degraded-volume&#34;&gt;Test degraded volume&lt;/h3&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;Verify that Longhorn doesn&amp;rsquo;t upgrade engine image for degraded volume.&lt;/li&gt;&#xA;&lt;li&gt;While the upgrade is happening, make a volume degraded and verify if the upgrade still happen.&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;h3 id=&#34;test-dr-volume&#34;&gt;Test DR volume&lt;/h3&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;Verify that Longhorn doesn&amp;rsquo;t upgrade engine image for DR volume.&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;h3 id=&#34;test-expanding-volume&#34;&gt;Test expanding volume&lt;/h3&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;Verify that Longhorn doesn&amp;rsquo;t upgrade engine image for volume which is expanding.&lt;/li&gt;&#xA;&lt;/ol&gt;</description>
    </item>
    <item>
      <title>Kubernetes upgrade test</title>
      <link>https://longhorn.github.io/longhorn-tests/manual/pre-release/upgrade/kubernetes-upgrade-test/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://longhorn.github.io/longhorn-tests/manual/pre-release/upgrade/kubernetes-upgrade-test/</guid>
      <description>&lt;p&gt;We also need to cover the Kubernetes upgrade process for supported Kubernetes version, make sure pod and volumes works after a major version upgrade.&lt;/p&gt;&#xA;&lt;h2 id=&#34;related-issue&#34;&gt;Related Issue&lt;/h2&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/longhorn/longhorn/issues/2566&#34;&gt;https://github.com/longhorn/longhorn/issues/2566&lt;/a&gt;&lt;/p&gt;&#xA;&lt;h2 id=&#34;test-with-k8s-upgrade&#34;&gt;Test with K8s upgrade&lt;/h2&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;Create a K8s (Immediate prior version) cluster with 3 worker nodes and 1 control plane.&lt;/li&gt;&#xA;&lt;li&gt;Deploy Longhorn version (Immediate prior version) on the cluster.&lt;/li&gt;&#xA;&lt;li&gt;Create a volume and attach to a pod.&lt;/li&gt;&#xA;&lt;li&gt;Write data to the volume and compute the checksum.&lt;/li&gt;&#xA;&lt;li&gt;Create 2nd volume and keep it detached.&lt;/li&gt;&#xA;&lt;li&gt;Upgrade K8s to the latest version.&lt;/li&gt;&#xA;&lt;li&gt;Observe the volume replicas get rebuilt as the instance manager goes down temporarily for the upgrade.&lt;/li&gt;&#xA;&lt;li&gt;Verify all the volume should come up healthy after all the nodes are upgraded.&lt;/li&gt;&#xA;&lt;li&gt;Upgrade Longhorn to the latest version and verify all the volumes become healthy eventually.&lt;/li&gt;&#xA;&lt;li&gt;Verify the data in the volume.&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;&lt;strong&gt;Known Issue&lt;/strong&gt;: If the volumes are still attaching and the instance managers got killed due to node went down temporarily for the upgrade, the replicas on those instance managers will be out of sync and will become error.&#xA;&lt;a href=&#34;https://github.com/longhorn/longhorn/issues/494&#34;&gt;https://github.com/longhorn/longhorn/issues/494&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>Longhorn Upgrade test</title>
      <link>https://longhorn.github.io/longhorn-tests/manual/pre-release/upgrade/longhorn-upgrade-test/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://longhorn.github.io/longhorn-tests/manual/pre-release/upgrade/longhorn-upgrade-test/</guid>
      <description>&lt;h3 id=&#34;setup&#34;&gt;Setup&lt;/h3&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;2 attached volumes with data. 2 detached volumes with data. 2 new volumes without data.&lt;/li&gt;&#xA;&lt;li&gt;2 deployments of one pod. 1 statefulset of 10 pods.&lt;/li&gt;&#xA;&lt;li&gt;&lt;code&gt;Auto Salvage&lt;/code&gt; set to disable.&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;h3 id=&#34;test&#34;&gt;Test&lt;/h3&gt;&#xA;&lt;p&gt;After upgrade:&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;Make sure the existing instance managers didn&amp;rsquo;t restart.&lt;/li&gt;&#xA;&lt;li&gt;Make sure pods didn&amp;rsquo;t restart.&lt;/li&gt;&#xA;&lt;li&gt;Check the contents of the volumes.&lt;/li&gt;&#xA;&lt;li&gt;If the Engine API version is incompatible, manager cannot do anything about the attached volumes except detaching it.&lt;/li&gt;&#xA;&lt;li&gt;If the Engine API version is incompatible, manager cannot live-upgrade the attached volumes.&lt;/li&gt;&#xA;&lt;li&gt;If the Engine API version is incompatible, manager cannot reattach an existing volume until the user has upgraded the engine image to a manager supported version.&lt;/li&gt;&#xA;&lt;li&gt;After offline or online (live) engine upgrade, check the contents of the volumes are valid.&lt;/li&gt;&#xA;&lt;li&gt;For the volume never been attached in the old version, check it&amp;rsquo;s attachable after the upgrade.&lt;/li&gt;&#xA;&lt;/ol&gt;</description>
    </item>
    <item>
      <title>Re-deploy CSI components when their images change</title>
      <link>https://longhorn.github.io/longhorn-tests/manual/pre-release/upgrade/update_csi_components_when_images_change/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://longhorn.github.io/longhorn-tests/manual/pre-release/upgrade/update_csi_components_when_images_change/</guid>
      <description>&lt;ol&gt;&#xA;&lt;li&gt;Install Longhorn&lt;/li&gt;&#xA;&lt;li&gt;Change the &lt;code&gt;longhorn-driver-deployer&lt;/code&gt; yaml at &lt;a href=&#34;https://github.com/longhorn/longhorn-manager/blob/c2ceb9f3f991810f811601d8c41c09b67fb50746/deploy/install/02-components/04-driver.yaml#L50&#34;&gt;https://github.com/longhorn/longhorn-manager/blob/c2ceb9f3f991810f811601d8c41c09b67fb50746/deploy/install/02-components/04-driver.yaml#L50&lt;/a&gt; to use the new images for some CSI components&lt;/li&gt;&#xA;&lt;li&gt;&lt;code&gt;Kubectl apply -f&lt;/code&gt; the &lt;code&gt;longhorn-driver-deployer&lt;/code&gt; yaml&lt;/li&gt;&#xA;&lt;li&gt;Verify that only CSI components with the new images are re-deployed and have new images&lt;/li&gt;&#xA;&lt;li&gt;Redeploy &lt;code&gt;longhorn-driver-deployer&lt;/code&gt; without changing the images.&lt;/li&gt;&#xA;&lt;li&gt;Verify that no CSI component is re-deployed&lt;/li&gt;&#xA;&lt;/ol&gt;</description>
    </item>
    <item>
      <title>Test Backing Image during Longhorn upgrade</title>
      <link>https://longhorn.github.io/longhorn-tests/manual/pre-release/upgrade/backing-image-during-upgrade/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://longhorn.github.io/longhorn-tests/manual/pre-release/upgrade/backing-image-during-upgrade/</guid>
      <description>&lt;h2 id=&#34;system-upgrade-with-compatible-backing-image-manager-image&#34;&gt;System upgrade with compatible backing image manager image&lt;/h2&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;Deploy Longhorn. Then set &lt;code&gt;Concurrent Automatic Engine Upgrade Per Node Limit&lt;/code&gt; to a positive value to enable volume engine auto upgrade.&lt;/li&gt;&#xA;&lt;li&gt;Create 2 backing images: a large one and a small one. Longhorn will start preparing the 1st file for both backing image immediately via launching backing image data source pods.&lt;/li&gt;&#xA;&lt;li&gt;Wait for the small backing image being ready in the 1st disk. Then create and attach volumes with the backing image.&lt;/li&gt;&#xA;&lt;li&gt;Wait for volumes attachment. Verify the backing image content then write random data in the volumes.&lt;/li&gt;&#xA;&lt;li&gt;Wait for the large backing image being ready in the 1st disk. Then create and attach one more volume with this large backing image.&lt;/li&gt;&#xA;&lt;li&gt;Before the large backing image is synced to other nodes and the volume becomes attached, upgrade the whole Longhorn system:&#xA;&lt;ol&gt;&#xA;&lt;li&gt;A new engine image will be used.&lt;/li&gt;&#xA;&lt;li&gt;The default backing image manager image will be updated.&lt;/li&gt;&#xA;&lt;li&gt;The new longhorn manager is compatible with the old backing image manager.&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;Wait for system upgrade complete. Then verify:&#xA;&lt;ol&gt;&#xA;&lt;li&gt;All old backing image manager and the related pod will be cleaned up automatically after the current downloading is complete. And the existing backing image files won&amp;rsquo;t be removed.&lt;/li&gt;&#xA;&lt;li&gt;New default backing image manager will take over all backing image ownerships and show the info in the status map:&#xA;&lt;ol&gt;&#xA;&lt;li&gt;For the small backing image, the new backing image manager will directly take over all ready files.&lt;/li&gt;&#xA;&lt;li&gt;For the large backing image, the new backing image manager will take over the only ready file and mark all in-progress files as failed first. Then it will re-sync the files after the backoff window.&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;All attached volumes still work fine without replica crash, and the content is correct in the volumes during/after the upgrade.&lt;/li&gt;&#xA;&lt;li&gt;The last volume get attached successfully without replica crash, and the content is correct.&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;Verify volumes and backing images can be deleted.&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;h2 id=&#34;system-upgrade-with-incompatible-backing-image-manager-image&#34;&gt;System upgrade with incompatible backing image manager image&lt;/h2&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;Deploy Longhorn.&lt;/li&gt;&#xA;&lt;li&gt;Create a backing images. Wait for the backing image being ready in the 1st disk.&lt;/li&gt;&#xA;&lt;li&gt;Create and attach volumes with the backing image.&lt;/li&gt;&#xA;&lt;li&gt;Wait for volumes attachment. Verify the backing image content then write random data in the volumes.&lt;/li&gt;&#xA;&lt;li&gt;Upgrade the whole Longhorn system:&#xA;&lt;ol&gt;&#xA;&lt;li&gt;The default backing image manager image will be updated.&lt;/li&gt;&#xA;&lt;li&gt;The new longhorn manager is not compatible with the old backing image manager.&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;Wait for system upgrade complete. Then verify:&#xA;&lt;ol&gt;&#xA;&lt;li&gt;All old incompatible backing image manager and the related pod will be cleaned up automatically.&lt;/li&gt;&#xA;&lt;li&gt;New default backing image manager will take over all backing image ownerships and show the info in the status map.&lt;/li&gt;&#xA;&lt;li&gt;All attached volumes still work fine without replica crash, and the content is correct in the volumes during/after the upgrade.&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;h3 id=&#34;system-upgrade-with-the-same-backing-image-manager-image&#34;&gt;System upgrade with the same backing image manager image&lt;/h3&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;Deploy Longhorn.&lt;/li&gt;&#xA;&lt;li&gt;Create a backing images. Wait for the backing image being ready in the 1st disk.&lt;/li&gt;&#xA;&lt;li&gt;Create and attach volumes with the backing image. Wait for all disk files of the backing image being ready.&lt;/li&gt;&#xA;&lt;li&gt;Run &lt;code&gt;kubectl -n longhorn system get pod -w&lt;/code&gt; in a seperate session.&lt;/li&gt;&#xA;&lt;li&gt;Upgrade Longhorn manager but with the backing image manager image unchanged. (Actually we can mock this upgrade by removing all longhorn manager pods simultaneously.)&lt;/li&gt;&#xA;&lt;li&gt;Check if all disk file status of the backing image becomes &lt;code&gt;unknown&lt;/code&gt; then &lt;code&gt;ready&lt;/code&gt; during the longhorn manager pods termination and restart. (May need to refresh the UI page after restart.)&lt;/li&gt;&#xA;&lt;li&gt;After the longhorn manager pods restart, Verify there is no backing image data source pod launched for the backing image in the output of step4.&lt;/li&gt;&#xA;&lt;li&gt;Repeat step4 ~ step8 for 10 times.&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;h4 id=&#34;available-test-backing-image-urls&#34;&gt;Available test backing image URLs:&lt;/h4&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;https://longhorn-backing-image.s3-us-west-1.amazonaws.com/parrot.qcow2&#xA;https://longhorn-backing-image.s3-us-west-1.amazonaws.com/parrot.raw&#xA;https://cloud-images.ubuntu.com/minimal/releases/focal/release-20200729/ubuntu-20.04-minimal-cloudimg-amd64.img&#xA;https://github.com/rancher/k3os/releases/download/v0.11.0/k3os-amd64.iso &#xA;&lt;/code&gt;&lt;/pre&gt;&lt;h4 id=&#34;the-way-to-generate-a-longhorn-manager-image-with-higher-api-version&#34;&gt;The way to generate a longhorn-manager image with higher API version&lt;/h4&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;Download longhorn manager repo with command &lt;code&gt;git clone https://github.com/longhorn/longhorn-manager.git&lt;/code&gt;.&lt;/li&gt;&#xA;&lt;li&gt;Increase the constant &lt;code&gt;CurrentBackingImageManagerAPIVersion&lt;/code&gt; in &lt;code&gt;longhorn-manager/engineapi/backing_image_manager.go&lt;/code&gt; by 1.&lt;/li&gt;&#xA;&lt;li&gt;Run &lt;code&gt;make&lt;/code&gt; to build a longhorn-manager image then push it to docker hub.&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;h4 id=&#34;the-way-to-generate-a-backing-image-manager-image-with-higher-api-version&#34;&gt;The way to generate a backing-image-manager image with higher API version&lt;/h4&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;Download backing image manager repo with command &lt;code&gt;git clone https://github.com/longhorn/backing-image-manager.git&lt;/code&gt;.&lt;/li&gt;&#xA;&lt;li&gt;Increase the constants &lt;code&gt;BackingImageManagerAPIVersion&lt;/code&gt; and &lt;code&gt;BackingImageManagerAPIMinVersion&lt;/code&gt; in &lt;code&gt;backing-image-manager/pkg/meta/version.go&lt;/code&gt; by 1.&lt;/li&gt;&#xA;&lt;li&gt;Run &lt;code&gt;make&lt;/code&gt; to build a longhorn-manager image then push it to docker hub.&lt;/li&gt;&#xA;&lt;/ol&gt;</description>
    </item>
    <item>
      <title>Test Engine Crash During Live Upgrade</title>
      <link>https://longhorn.github.io/longhorn-tests/manual/pre-release/upgrade/engine-crash-during-live-upgrade/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://longhorn.github.io/longhorn-tests/manual/pre-release/upgrade/engine-crash-during-live-upgrade/</guid>
      <description>&lt;ol&gt;&#xA;&lt;li&gt;Create and attach a volume.&lt;/li&gt;&#xA;&lt;li&gt;Deploy an extra engine image.&lt;/li&gt;&#xA;&lt;li&gt;Send live upgrade request then immediately delete the related engine manager pod/engine process (The new replicas are not in active in this case).&lt;/li&gt;&#xA;&lt;li&gt;Verify the volume will detach then reattach automatically.&lt;/li&gt;&#xA;&lt;li&gt;Verify the upgrade is done during the reattachment. (It actually becomes offline upgrade.)&lt;/li&gt;&#xA;&lt;/ol&gt;</description>
    </item>
    <item>
      <title>Test Node Drain Policy Setting</title>
      <link>https://longhorn.github.io/longhorn-tests/manual/pre-release/upgrade/test-node-drain-policy/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://longhorn.github.io/longhorn-tests/manual/pre-release/upgrade/test-node-drain-policy/</guid>
      <description>&lt;h2 id=&#34;with-node-drain-policy-is-block-if-contains-last-replica&#34;&gt;With &lt;code&gt;node-drain-policy&lt;/code&gt; is &lt;code&gt;block-if-contains-last-replica&lt;/code&gt;&lt;/h2&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;Note:&#xA;Starting from v1.5.x, it is not necessary to check for the presence of longhorn-admission-webhook and longhorn-conversion-webhook.&#xA;Please refer to the Longhorn issue &lt;a href=&#34;https://github.com/longhorn/longhorn/issues/5590&#34;&gt;#5590&lt;/a&gt; for more details.&lt;/p&gt;&#xA;&lt;p&gt;Starting from v1.5.x, observe that the instance-manager-r and instance-manager-e are combined into instance-manager.&#xA;Ref &lt;a href=&#34;https://github.com/longhorn/longhorn/issues/5208&#34;&gt;5208&lt;/a&gt;&lt;/p&gt;&lt;/blockquote&gt;&#xA;&lt;h3 id=&#34;1-basic-unit-tests&#34;&gt;1. Basic unit tests&lt;/h3&gt;&#xA;&lt;h4 id=&#34;11-single-worker-node-cluster-with-separate-master-node&#34;&gt;1.1 Single worker node cluster with separate master node&lt;/h4&gt;&#xA;&lt;p&gt;1.1.1 RWO volumes&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Deploy Longhorn&lt;/li&gt;&#xA;&lt;li&gt;Verify that there is no PDB for &lt;code&gt;csi-attacher&lt;/code&gt;, &lt;code&gt;csi-provisioner&lt;/code&gt;, &lt;code&gt;longhorn-admission-webhook&lt;/code&gt;, and &lt;code&gt;longhorn-conversion-webhook&lt;/code&gt;&lt;/li&gt;&#xA;&lt;li&gt;Manually create a PVC (simulate the volume which has never been attached scenario)&lt;/li&gt;&#xA;&lt;li&gt;Verify that there is no PDB for &lt;code&gt;csi-attacher&lt;/code&gt;, &lt;code&gt;csi-provisioner&lt;/code&gt;, &lt;code&gt;longhorn-admission-webhook&lt;/code&gt;, and &lt;code&gt;longhorn-conversion-webhook&lt;/code&gt; because there is no attached volume&lt;/li&gt;&#xA;&lt;li&gt;Create a deployment that uses one RW0 Longhorn volume.&lt;/li&gt;&#xA;&lt;li&gt;Verify that there is PDB for &lt;code&gt;csi-attacher&lt;/code&gt;, &lt;code&gt;csi-provisioner&lt;/code&gt;, &lt;code&gt;longhorn-admission-webhook&lt;/code&gt;, and &lt;code&gt;longhorn-conversion-webhook&lt;/code&gt;&lt;/li&gt;&#xA;&lt;li&gt;Create another deployment that uses one RWO Longhorn volume. Scale down this deployment so that the volume is detached&lt;/li&gt;&#xA;&lt;li&gt;Drain the node by &lt;code&gt;kubectl drain &amp;lt;node-name&amp;gt; --ignore-daemonsets --delete-emptydir-data --force&lt;/code&gt;&lt;/li&gt;&#xA;&lt;li&gt;Observe that the workload pods are evited first -&amp;gt; PDB of &lt;code&gt;csi-attacher&lt;/code&gt;, &lt;code&gt;csi-provisioner&lt;/code&gt;, &lt;code&gt;longhorn-admission-webhook&lt;/code&gt;, and &lt;code&gt;longhorn-conversion-webhook&lt;/code&gt; are removed -&amp;gt; &lt;code&gt;csi-attacher&lt;/code&gt;, &lt;code&gt;csi-provisioner&lt;/code&gt;, &lt;code&gt;longhorn-admission-webhook&lt;/code&gt;, and &lt;code&gt;longhorn-conversion-webhook&lt;/code&gt;, and instance-manager-e pods are evicted -&amp;gt; all volumes are successfully detached&lt;/li&gt;&#xA;&lt;li&gt;Observe that instance-manager-r is NOT evicted.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;1.1.2 RWX volume&lt;/p&gt;</description>
    </item>
    <item>
      <title>Test system upgrade with a new storage class being default</title>
      <link>https://longhorn.github.io/longhorn-tests/manual/pre-release/upgrade/upgrade-with-customized-storage-class/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://longhorn.github.io/longhorn-tests/manual/pre-release/upgrade/upgrade-with-customized-storage-class/</guid>
      <description>&lt;ol&gt;&#xA;&lt;li&gt;Install a previous stable Longhorn on a K8s cluster.&lt;/li&gt;&#xA;&lt;li&gt;Create a storage class &amp;rsquo;longhorn-rep-2&amp;rsquo; with replica 2 and make it default.&lt;/li&gt;&#xA;&lt;li&gt;Create some volumes with the above created storage class and attach them to workloads.&lt;/li&gt;&#xA;&lt;li&gt;Upgrade Longhorn to latest version.&lt;/li&gt;&#xA;&lt;li&gt;Longhorn should be upgraded.&lt;/li&gt;&#xA;&lt;li&gt;Storage class &amp;rsquo;longhorn-rep-2&amp;rsquo; should be the default storage class.&lt;/li&gt;&#xA;&lt;li&gt;Create two volumes, one with &amp;rsquo;longhorn&amp;rsquo; storage class and other with &amp;rsquo;longhorn-rep-2&#39;.&lt;/li&gt;&#xA;&lt;li&gt;Verify the volumes are created as per their storage class.&lt;/li&gt;&#xA;&lt;/ol&gt;</description>
    </item>
    <item>
      <title>Test System Upgrade with New Instance Manager</title>
      <link>https://longhorn.github.io/longhorn-tests/manual/pre-release/upgrade/upgrade-with-new-instance-manager/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://longhorn.github.io/longhorn-tests/manual/pre-release/upgrade/upgrade-with-new-instance-manager/</guid>
      <description>&lt;ol&gt;&#xA;&lt;li&gt;Prepare 3 sets of longhorn-manager and longhorn-instance-manager images.&lt;/li&gt;&#xA;&lt;li&gt;Deploy Longhorn with the 1st set of images.&lt;/li&gt;&#xA;&lt;li&gt;Set &lt;code&gt;Guaranteed Instance Manager CPU&lt;/code&gt; to 40, respectively.&#xA;Then wait for the instance manager recreation.&lt;/li&gt;&#xA;&lt;li&gt;Create and attach a volume to a node (node1).&lt;/li&gt;&#xA;&lt;li&gt;Upgrade the Longhorn system with the 2nd set of images.&#xA;Verify the CPU requests in the pods of both instance managers match the settings.&lt;/li&gt;&#xA;&lt;li&gt;Create and attach one more volume to node1.&lt;/li&gt;&#xA;&lt;li&gt;Upgrade the Longhorn system with the 3rd set of images.&lt;/li&gt;&#xA;&lt;li&gt;Verify the pods of the 3rd instance manager cannot be launched on node1 since there is no available CPU for the allocation.&lt;/li&gt;&#xA;&lt;li&gt;Detach the volume in the 1st instance manager pod.&#xA;Verify the related instance manager pods will be cleaned up and the new instance manager pod can be launched on node1.&lt;/li&gt;&#xA;&lt;/ol&gt;</description>
    </item>
    <item>
      <title>Upgrade Conflict Handling test</title>
      <link>https://longhorn.github.io/longhorn-tests/manual/pre-release/upgrade/upgrade-conflict-handling/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://longhorn.github.io/longhorn-tests/manual/pre-release/upgrade/upgrade-conflict-handling/</guid>
      <description>&lt;h3 id=&#34;new-installation&#34;&gt;New installation:&lt;/h3&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;Create a large cluster of many nodes (about 30 nodes)&lt;/li&gt;&#xA;&lt;li&gt;Install Longhorn &lt;code&gt;master&lt;/code&gt;&lt;/li&gt;&#xA;&lt;li&gt;Create 100 volumes using volume template claim in statefulSet.&lt;/li&gt;&#xA;&lt;li&gt;Have the backup store configured and create some backups.&lt;/li&gt;&#xA;&lt;li&gt;Set some recurring jobs in the cluster every 1 minute.&lt;/li&gt;&#xA;&lt;li&gt;Observe the setup for 1/2 an hr. Do some operation like attaching detaching the volumes.&lt;/li&gt;&#xA;&lt;li&gt;Verify there is no error in the Longhorn manager.&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;h3 id=&#34;upgrading-from-old-version&#34;&gt;Upgrading from old version:&lt;/h3&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;Repeat the steps from above test case with Longhorn Prior version.&lt;/li&gt;&#xA;&lt;li&gt;Upgrade Longhorn to &lt;code&gt;master&lt;/code&gt;.&lt;/li&gt;&#xA;&lt;li&gt;Do some operation like attaching and detaching the volumes.&lt;/li&gt;&#xA;&lt;li&gt;Verify there is no error in the Longhorn manager.&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;&lt;strong&gt;Success if:&lt;/strong&gt; install/upgrade successfully after maximum 15 minutes.&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
